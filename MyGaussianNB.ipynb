{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47750 Machine Learning Assignment\n",
    "# Gaussian Naive Bayes\n",
    "A reimplementation of the `sklearn` Gaussian Naive Bayes classifier. \n",
    "\n",
    "1. Provide a python class MyGaussianNB that implements Gaussian Naive Bayes. \n",
    "The API specification for sklearn classifiers is here: https://scikit-learn.org/stable/developers/develop.html \n",
    "You should implement the ‘fit’ and ‘predict’ methods, there is no need to implement ‘predict_proba’. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My GaussianNB\n",
    "Reimplementation of a Gaussian Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNB(BaseEstimator, ClassifierMixin):          \n",
    "    def fit(self, Xt, yt):\n",
    "        self.var_smoothing = 1e-9   # zero variance will cause division by zero errors.\n",
    "        self.Xt = Xt\n",
    "        self.yt = yt\n",
    "        self.n_feat = Xt.shape[1]\n",
    "        self.mus = {}\n",
    "        self.sig_sqs = {}\n",
    "        self.priors = {}\n",
    "        \n",
    "        c_dict = Counter(self.yt)\n",
    "        \n",
    "        for c in c_dict.keys():\n",
    "            self.mus[c] = np.zeros(self.n_feat) # where the means will be stored\n",
    "            self.sig_sqs[c] = np.zeros(self.n_feat) # where the variances will be stored\n",
    "            self.priors[c] = c_dict[c]/Xt.shape[0]\n",
    "            \n",
    "            mask = self.yt == c\n",
    "            X_tr_c = self.Xt[mask, :] # the rows for this class label\n",
    "            \n",
    "            for f in range(self.n_feat):\n",
    "                self.mus[c][f] = np.mean(X_tr_c[:,f])\n",
    "                self.sig_sqs[c][f] = np.var(X_tr_c[:,f] + self.var_smoothing)  #var              \n",
    "        #print(self.mus)\n",
    "        #print(self.sig_sqs)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    # The predictions are the most common class in the training set.\n",
    "    def predict(self, Xtes):\n",
    "        #print(\"Predicting MGNB\")\n",
    "        self.Xtes = Xtes\n",
    "         \n",
    "        res_list = []\n",
    "        for sample in Xtes:\n",
    "            res_list.append(self.predict_single(sample))\n",
    "            \n",
    "        return np.array(res_list)\n",
    "    \n",
    "    def predict_single(self, x_single):\n",
    "        probs = {}\n",
    "        for c in self.priors.keys():   # for each of the class labels\n",
    "            probs[c] = self.priors[c]\n",
    "            for i, f in enumerate(x_single):\n",
    "                t1 = 1/math.sqrt(2*math.pi*self.sig_sqs[c][i])\n",
    "                num = (f - self.mus[c][i])**2\n",
    "                den = 2*self.sig_sqs[c][i]\n",
    "                pxi_y = t1 * math.exp(-num/den)\n",
    "                probs[c] = probs[c] * pxi_y\n",
    "                #print(t1, num, den, pxi_y)\n",
    "                #print(probs)\n",
    "            #print(c, self.priors[c])\n",
    "        return max(probs, key=probs.get) # Return the key with the largest value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "2. Test the performance of your implementation against the `GaussianNB` implementation in `scikit-learn`. You should use a range of datasets for this testing.   \n",
    "Four datasets are used for testing; testing on a hold out set:\n",
    " - **penguins**: check that mean and variance estimates are the same, check that predictions are the same. \n",
    " - **diabetes**: check that predictions are the same.\n",
    " - **glassV2**: test that predictions are the same. \n",
    " - **bike_sharing**: test that predictions are the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main component in the testing is to check the `fidelity` of the testing against the Gaussian Naive Bayes implementation in `scikit-learn`.    \n",
    "The `fidelity_tests` function compares predictions across multiple runs (different holdout tests). It uses `accuracy_score` to do the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_tests (X,y, nreps = 10):\n",
    "    for rs in range(1, nreps + 1):\n",
    "        X_tr_raw, X_ts_raw, y_train, y_test = train_test_split(X_raw, y, \n",
    "                                                               random_state=rs, \n",
    "                                                               test_size=1/2)\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_tr_raw)\n",
    "        X_test = scaler.transform(X_ts_raw)\n",
    "        gnb = GaussianNB()\n",
    "        mgnb = MyGaussianNB()\n",
    "        mgnb.fit(X_train,y_train)\n",
    "        gnb.fit(X_train,y_train)\n",
    "        ascore = accuracy_score(gnb.predict(X_test),mgnb.predict(X_test)) \n",
    "        gacc = accuracy_score(gnb.predict(X_test),y_test)\n",
    "        macc = accuracy_score(mgnb.predict(X_test),y_test)\n",
    "        print (\"Run: %d Score: %.2f SK acc: %.2f My acc: %.2f\" % (rs, ascore, gacc, macc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "4       3450.0  female  2007  \n",
       "5       3650.0    male  2007  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins = pd.read_csv('penguins_af.csv', index_col = 0)\n",
    "print(penguins.shape)\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = penguins.pop('species')\n",
    "# penguins = pd.get_dummies(penguins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Torgersen', 39.1, 18.7, 181.0, 3750.0, 'male', 2007], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((166, 10), (167, 10))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_raw = penguins.values\n",
    "X_tr_raw, X_ts_raw, y_train, y_test = train_test_split(X_raw, y, random_state=2, test_size=1/2)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_tr_raw)\n",
    "X_test = scaler.transform(X_ts_raw)\n",
    "max_k = X_train.shape[1]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4451256 ,  0.67719924, -0.72189828, -0.8968907 , -1.36135792,\n",
       "       -1.        ,  1.26243812, -0.35951593,  1.04941213, -1.04941213])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Parameters**  \n",
    "The means are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "mgnb = MyGaussianNB()\n",
    "mgnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgnb.sig_sqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.theta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mgnb.mus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy scores are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fidelity tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the lables of the predictions of the first 10 test samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mgnb.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run multiple tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fidelity_tests(X_raw, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use `accuracy_score` to compare all predictions on the test set.   \n",
    "The score of 1.0 indicates perfect agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes dataset  \n",
    "Test that the predictions are the same on a holdout set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes.csv') #, index_col = 0)\n",
    "print(diabetes.shape)\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diabetes.pop('neg_pos').values\n",
    "X_raw = diabetes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelity_tests(X_raw, y, nreps = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glass Dataset\n",
    "Test that the predictions are the same on a holdout set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = pd.read_csv('glassV2.csv') #, index_col = 0)\n",
    "print(glass.shape)\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_orig = pd.read_csv('glassV2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_orig['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = glass_orig[glass_orig['Type'].isin([1,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = glass.pop('Type')\n",
    "X_raw = glass.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelity_tests(X_raw, y, nreps = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One miss-match here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bike Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bikes_df = pd.read_csv('bike_sharing.csv')\n",
    "bikes_df.head()\n",
    "bikes_df['usage'] = 'Low'\n",
    "bikes_df.loc[bikes_df['count'] > 4500, 'usage'] = 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_df['usage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bikes_df.pop('usage').values\n",
    "bikes_df.pop('casual').values\n",
    "bikes_df.pop('registered').values\n",
    "bikes_df.pop('instant').values\n",
    "bikes_df.pop('dteday').values\n",
    "bikes_df.pop('count').values\n",
    "X_raw = bikes_df.values\n",
    "X_raw.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelity_tests(X_raw, y, nreps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
