{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "np.set_printoptions(suppress=True)\n",
    "import math\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNB(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.__mean_std_dict = {}\n",
    "        \n",
    "        # find each unique class and for each of these classes\n",
    "        classes = np.unique(y)\n",
    "        for c in classes:\n",
    "            # get all indicies for this class\n",
    "            indices = np.where(y==c)\n",
    "            \n",
    "            self.__mean_std_dict[c] = {'prior_prob':(len(indices[0])/len(X))}\n",
    "            \n",
    "            # for each column of this class, find the mean and std\n",
    "            for i in range(len(X[0])):\n",
    "                \n",
    "                # for the current class and the current column, find the inidices of the \n",
    "                # training set where the class is equal to the current class and \n",
    "                # the current column is not null\n",
    "                notNull = np.where((y==c)&(np.isnan(X[:,i])==False))\n",
    "                \n",
    "                # calculate the mean and std based on these values\n",
    "                self.__mean_std_dict[c][i] = {'mean':(X[notNull,i].mean()), 'std':(X[notNull,i].std())}\n",
    "            \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        self.X = X\n",
    "        \n",
    "        predictions = np.empty([0,len(X)])\n",
    "        \n",
    "        def conditionalProba(val, mean, stdev):\n",
    "            '''\n",
    "            Function that takes a value, a mean value and a standard deviation value.\n",
    "            It inputs these into a formula supplied in the assignment question and outputs the\n",
    "            resulting conditional probability for each value.\n",
    "            '''\n",
    "            \n",
    "            if stdev == 0:\n",
    "                if val == mean:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "                \n",
    "            probability = (1/(2*np.pi*(stdev**2))**0.5) * np.exp(-((val-mean)**2)/(2*(stdev**2)))\n",
    "            return probability\n",
    "        \n",
    "        classes = self.__mean_std_dict.keys()\n",
    "        \n",
    "        # go through each row of the training data\n",
    "        # for each row\n",
    "            # make a dictionary for probabilities for each possible class\n",
    "            \n",
    "        for i in range(len(X)):\n",
    "            probDict = {}\n",
    "            currentRow = X[i]\n",
    "            \n",
    "            # for each possible class\n",
    "                # add a list that includes the current class's prior probability to current\n",
    "                # class key in the dictionary\n",
    "            for c in classes:\n",
    "                probDict[c] = [self.__mean_std_dict[c]['prior_prob']]\n",
    "                \n",
    "                # for each column value in the current row\n",
    "                    # find the mean and std for this column and class in the mean_std_dict\n",
    "                    # plug the current column value, the mean for this column and the std\n",
    "                    # for this column into the conditionalProba() function\n",
    "                    # append the value returned from this to the current class key in the\n",
    "                    # probability dictionary\n",
    "                for j in range(len(currentRow)):\n",
    "                    val = currentRow[j]\n",
    "                    if math.isnan(val):\n",
    "                        continue\n",
    "                    mean = self.__mean_std_dict[c][j]['mean']\n",
    "                    std = self.__mean_std_dict[c][j]['std']\n",
    "                    probDict[c].append(conditionalProba(val, mean, std))\n",
    "                    \n",
    "                # when the conditional probabilities for each column have been added to the dictionary\n",
    "                # get the product of each of these values and assign it to the probability dictionary\n",
    "                # for the current class\n",
    "                probDict[c] = np.prod(probDict[c])\n",
    "                \n",
    "            # normalise the probabilities for each class\n",
    "            total = sum(probDict.values())\n",
    "            for k in probDict.keys():\n",
    "                val = probDict[k]\n",
    "                probDict[k] = val/total\n",
    "                \n",
    "            # get the class name with the highest normalised probability from the dictionary values\n",
    "            # append the class name to the list of predictions\n",
    "            index = list(probDict.values()).index(max(probDict.values()))\n",
    "            predictions = np.append(predictions, list(probDict.keys())[index])\n",
    "            \n",
    "        # return the list of predictions\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes made to MyGaussianNB() object to allow for missing values:\n",
    "- In the training phase, when calculating the mean and standard deviation of each feature given the class, just the entries that have a numerical value for the feature are used. That is to say, if the feature value is NaN, then it is not used in caluclating the mean and standard deviation.\n",
    "- In the prediction phase, when calculating the conditional probability for each feature for each class, once again just the entries that have a numerical value for the feature are used. If the feature has a value of NaN, it is not used in calculating the conditional probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process:\n",
    "- I will be creating models for 2 datasets: PenguinsMV0.2.csv and PenguinsMV0.4.csv, using the MyGaussianNB class defined above.\n",
    "- As each of the datasets are small, I will evaluate each model's performance using 5-fold cross-validation. This will give a more robust evaluation of each model's performance.\n",
    "- I will compare the models created by MyGaussianNB to models created with scikit-learn's GaussianNB class across the following scores:\n",
    "    - accuracy\n",
    "    - confusion matrices\n",
    "    - precision\n",
    "    - recall\n",
    "    - f1 score\n",
    "    - balanced accuracy score (as each of the datasets is skewed towards one or more results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and format penguins data missing 20% of its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins20 = pd.read_csv(\"PenguinsMV0.2.csv\", index_col = 0)\n",
    "y = penguins20.pop(\"species\")\n",
    "X = penguins20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitute \"?\" for NaN\n",
    "for col in X.columns:\n",
    "    X.loc[X[col]==\"?\", col] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types to float\n",
    "X['bill_length'] = X['bill_length'].astype('float64')\n",
    "X['bill_depth'] = X['bill_depth'].astype('float64')\n",
    "X['flipper_length'] = X['flipper_length'].astype('float64')\n",
    "X['body_mass'] = X['body_mass'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation versus my own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myGaussianPipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', MyGaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UVgaussianNBpipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values=np.NaN, strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVgaussianNBpipe = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=19, random_state=0)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penguins_20\n",
    "\n",
    "data = \"penguins_20\"\n",
    "pipeLines = [myGaussianPipe, UVgaussianNBpipe, MVgaussianNBpipe]\n",
    "pipeNames = [\"myGaussianPipe\", \"uniVariateGaussianNBpipe\", \"multiVariateGaussianNBpipe\"]\n",
    "\n",
    "print(f'Classes are {y.unique()}')\n",
    "\n",
    "for i in range(len(pipeLines)):\n",
    "    m = pipeLines[i]\n",
    "    print(\"------------------------------------\")\n",
    "    print(pipeNames[i], \"data:\", data)\n",
    "    print(\"------------------------------------\")\n",
    "    accuracy = cross_val_score(m, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"accuracy: {accuracy.mean()}\")\n",
    "    \n",
    "    y_pred = cross_val_predict(m, X, y, cv=5)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    print(f\"confusion matrix: \\n{conf_mat}\")\n",
    "    \n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    print(f\"precision score: {precision}\")\n",
    "    \n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "    print(f\"recall score: {recall}\")\n",
    "    \n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    print(f\"f1 score: {f1}\")\n",
    "    \n",
    "    bas = balanced_accuracy_score(y, y_pred)\n",
    "    print(f\"balanced accuracy score: {bas}\")\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation versus my own implementation with data missing 20% of its values – conclusions:\n",
    "- As we can see the MyGaussianNB class performed slightly better across all metrics than the GaussianNB class using both uni-variate and multi-variate imputation.\n",
    "- As we can see from the confusion matrix, the MyGaussianNB class performed better overall, although the GaussianNB class using multivariate imputation performed slightly better in predicting the second class with one more true positive than the MyGaussianNB class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and format penguins data missing 40% of its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins40 = pd.read_csv(\"PenguinsMV0.4.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = penguins40.pop(\"species\")\n",
    "X = penguins40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitute \"?\" for NaN\n",
    "for col in X.columns:\n",
    "    X.loc[X[col]==\"?\", col] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['bill_length'] = X['bill_length'].astype('float64')\n",
    "X['bill_depth'] = X['bill_depth'].astype('float64')\n",
    "X['flipper_length'] = X['flipper_length'].astype('float64')\n",
    "X['body_mass'] = X['body_mass'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation versus my own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myGaussianPipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', MyGaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UVgaussianNBpipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values=np.NaN, strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVgaussianNBpipe = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=33, random_state=0)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penguins_40\n",
    "\n",
    "data = \"penguins_40\"\n",
    "pipeLines = [myGaussianPipe, UVgaussianNBpipe, MVgaussianNBpipe]\n",
    "pipeNames = [\"myGaussianPipe\", \"uniVariateGaussianNBpipe\", \"multiVariateGaussianNBpipe\"]\n",
    "\n",
    "print(f'Classes are {y.unique()}')\n",
    "\n",
    "for i in range(len(pipeLines)):\n",
    "    m = pipeLines[i]\n",
    "    print(\"------------------------------------\")\n",
    "    print(pipeNames[i], \"data:\", data)\n",
    "    print(\"------------------------------------\")\n",
    "    accuracy = cross_val_score(m, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"accuracy: {accuracy.mean()}\")\n",
    "    \n",
    "    y_pred = cross_val_predict(m, X, y, cv=5)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    print(f\"confusion matrix: \\n{conf_mat}\")\n",
    "    \n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    print(f\"precision score: {precision}\")\n",
    "    \n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "    print(f\"recall score: {recall}\")\n",
    "    \n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    print(f\"f1 score: {f1}\")\n",
    "    \n",
    "    bas = balanced_accuracy_score(y, y_pred)\n",
    "    print(f\"balanced accuracy score: {bas}\")\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation versus my own implementation with data missing 40% of its values – conclusions:\n",
    "- We can see here that the three classes performed worse when the data was missing 40% of its values compared with 20%.\n",
    "- As we can see the MyGaussianNB class performed slightly better across all metrics than the GaussianNB class using both uni-variate and multi-variate imputation.\n",
    "- As we can see from the confusion matrix, the MyGaussianNB class performed better than the GaussianNB class with multi-variate imputation in predicting the first class with 134 true positives compared to 122, although the GaussianNB class using multivariate imputation performed slightly better in predicting the the second and third classes.\n",
    "- The MyGaussianNB class performed better than the GaussianNB class with uni-variate imputation in predicting the second and third classes, but slightly worse in predicting the first class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final conclusions:\n",
    "- The MyGaussianNB class performed notably better than the GaussianNB class using and uni-variate and multi-variate imputation in both multiclass datasets. The performance of both classifiers dropped when tested on a dataset with more missing values, but the MyGaussianNB class still outperformed the GaussianNB class using both imputations in all metrics.\n",
    "- This leads to my over all conclusion that the MyGaussianNB classifier is a more accurate classifier than the scikit-learn GaussianNB classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
